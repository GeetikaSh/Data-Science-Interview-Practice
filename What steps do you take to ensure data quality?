**What steps do you take to ensure data quality?**

Ensuring data quality is crucial for reliable insights and outcomes. Here are the steps I typically follow:

1. **Understand the Source and Context**  
   - Collaborate with data owners and stakeholders to understand the data's source, purpose, and key business requirements.

2. **Data Profiling**  
   - Use tools or write scripts to analyze data distributions, check for missing values, and detect outliers or anomalies.

3. **Validation Against Business Rules**  
   - Cross-check the data against predefined business rules and logic to ensure it aligns with expectations.

4. **Automated Data Cleansing**  
   - Apply ETL (Extract, Transform, Load) processes to handle missing, duplicate, or inconsistent records.

5. **Data Pipeline Testing**  
   - Build automated tests to validate data integrity throughout the pipeline.

6. **Documentation**  
   - Maintain a clear record of data sources, transformations, and quality checks for transparency and reproducibility.

7. **Continuous Monitoring**  
   - Set up monitoring systems to detect future data quality issues proactively.

This structured approach has helped me deliver high-quality data models and analyses throughout my career.
